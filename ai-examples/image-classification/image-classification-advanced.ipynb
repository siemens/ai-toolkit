{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "SPDX-License-Identifier": "MIT",
    "copyright": "Copyright 2020 Siemens AG"
   },
   "source": [
    "# Advanced Example for Image Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "import tensorflow.compat.v1 as tf \n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.compat.v1.keras import backend as tfKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensorflow: {}, tensorflow_hub: {}'.format(tf.__version__, hub.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset for training\n",
    "Extracting image set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tarfile.open('../../datasets/simatic_photos.tgz', 'r:gz') as f:\n",
    "    f.extractall(path = 'build/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect directory names to be used as class labels (directory names starting with a . character are filtered):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'build/simatic_photos'\n",
    "class_labels = [x for x in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir,x)) and x[0]!='.']\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224,224)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO) # verbosity is set to suppress unnecessary warnings about tensorflow 1.x being deprecated\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
    "training_set = image_generator.flow_from_directory(str(image_dir), target_size=IMAGE_SIZE, subset='training')\n",
    "validation_set = image_generator.flow_from_directory(str(image_dir), target_size=IMAGE_SIZE, subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator test\n",
    "Show a few images for visual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in training_set:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(class_labels[np.array(label_batch[n]).argmax()])\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Simatic devices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving MobileNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE+(3,))) \n",
    "feature_extractor.trainable=False\n",
    "print(f'Type of feature extractor: {type(feature_extractor)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model \n",
    "Extend the MobileNet with an additional softmax dense layer, which will be trained to do the final labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "x=feature_extractor.output\n",
    "x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# x=tf.keras.layers.Dense(label_batch.shape[1] ** 2,activation='relu')(x) # making the model more accurate, you can extend it with additional hidden layers\n",
    "classifier=tf.keras.layers.Dense(label_batch.shape[1],activation='softmax')(x) # final layer with softmax activation\n",
    "\n",
    "model=tf.keras.Model(inputs=feature_extractor.input,outputs=classifier)\n",
    "    \n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer = tf.keras.optimizers.Adam(),\n",
    "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "  metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback method for collecting logs\n",
    "Before you start training the model, define a callable class which stores the results (loss, accuracy, validation_loss, validation_accuracy) from each batch iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "    self.validation_losses = []\n",
    "    self.validation_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    try:\n",
    "        self.validation_losses.append(logs['val_loss'])\n",
    "        self.validation_acc.append(logs['val_acc'])\n",
    "    except:\n",
    "        self.validation_losses.append(None)\n",
    "        self.validation_acc.append(None)\n",
    "    self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization (optional)\n",
    "It is possible to visualize some details of a training using TensorBoard. You can run TensorBoard in advance to have a continuous visualization, or run it after everything is done to have an overview. TensorBoard reads and visualizes the logs of a training. Thus, if it is started in advance, then it might show a \"No dashboard\" message, or a previous training first, but it should load some graphs shortly after the training starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir build/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some environments cannot clean up Tensorboard temp files, which leads to an error message when the tensorboard is started, \n",
    "# saying that you have to kill the process. In such cases uncomment the following lines, or delete the .temp files manually, \n",
    "# and try running tensorboard again.\n",
    "\n",
    "#tempdir = os.path.join(tempfile.gettempdir(), \".tensorboard-info\")\n",
    "#if os.path.exists(tempdir):\n",
    "#    shutil.rmtree(tempdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Using a different network than MobileNet might require the adjustment of the epoch number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(training_set.samples/training_set.batch_size)\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.path.realpath('build/training')) \n",
    "\n",
    "history = model.fit_generator(training_set, epochs=25,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_data=validation_set,\n",
    "                              callbacks = [batch_stats_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating result\n",
    "Now that the training is done, you can visualize how model accuracy changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Accuracy during training\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1.2])\n",
    "plt.plot(batch_stats_callback.batch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in validation_set:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image_batch)\n",
    "predicted_class = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the images with their predicted class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(f'pred: {class_labels[predicted_class[n]]}\\norig: {class_labels[np.array(label_batch[n]).argmax()]}')\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Simatic devices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model\n",
    "If everything went well, the trained model is ready, it can be used as the neural network in the AI Template.\n",
    "As a final step, you need to save it in a \\*.h5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"build/simatic_mobilnet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving labels\n",
    "In order to map the results of the network to the expected labels, create a list of labels and save it in a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('build/simatic_labels.txt','w') as f:\n",
    "  f.write('\\n'.join(class_labels)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (image-classification)",
   "language": "python",
   "name": "image-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
